{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28b0db39",
   "metadata": {},
   "source": [
    "## Import the necessary packages, libraries, classes and methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef900daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all the necessary packages\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from disfdata import DisflQA\n",
    "from encdecmod import LSTM_ED, WordEmbedding, EarlyStopping\n",
    "from extrastuff import train, test, save, load\n",
    "\n",
    "import json\n",
    "import sentencepiece as spm\n",
    "import glob\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from nltk.translate.bleu_score import corpus_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a4d1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "json_file = open('./Datasets/Disfl-QA/train.json')\n",
    "data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4da7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the text files to write the original and disfluent sentences to\n",
    "original_txt_file = open('./Datasets/Disfl-QA/original.txt','w',encoding='utf-8')\n",
    "disfluent_txt_file = open('./Datasets/Disfl-QA/disfluent.txt','w',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef52faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract tokens & frequency from sentences\n",
    "for k,v in data.items():\n",
    "\n",
    "    original_txt_file.write(v['original'].lower() + '\\n')\n",
    "    disfluent_txt_file.write(v['disfluent'].lower() + '\\n')\n",
    "\n",
    "original_txt_file.close()\n",
    "disfluent_txt_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88b5edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build vocabulary with sentencepiece\n",
    "punc_list = ['`','~','!','@','#','$','%','^','&','*','-','_','+','=',\n",
    "             '\\\\','|',':',';','\"','\\'',',','.','?','/',\n",
    "             '(',')','{','}','[',']','<','>'] # punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d55775",
   "metadata": {},
   "outputs": [],
   "source": [
    "spm.SentencePieceTrainer.Train(\n",
    "    input='./Datasets/Disfl-QA/disfluent.txt', \n",
    "    model_prefix='./Datasets/Disfl-QA/spm_disfluent', \n",
    "    vocab_size=1000, \n",
    "    model_type='unigram',\n",
    "    unk_id=0, bos_id=1, eos_id=2, pad_id=3,\n",
    "    user_defined_symbols=punc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021b7f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "spm.SentencePieceTrainer.Train(\n",
    "    input='./Datasets/Disfl-QA/original.txt', \n",
    "    model_prefix='./Datasets/Disfl-QA/spm_original', \n",
    "    vocab_size=1000, \n",
    "    model_type='unigram',\n",
    "    unk_id=0, bos_id=1, eos_id=2, pad_id=3,\n",
    "    user_defined_symbols=punc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9161132e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spm.SentencePieceTrainer.Train(\n",
    "    input=glob.glob('./Datasets/Disfl-QA/*.txt'), \n",
    "    model_prefix='./Datasets/Disfl-QA/spm', \n",
    "    vocab_size=1000, \n",
    "    model_type='unigram',\n",
    "    unk_id=0, bos_id=1, eos_id=2, pad_id=3,\n",
    "    user_defined_symbols=punc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a28845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "sp_dis = spm.SentencePieceProcessor(model_file='./Datasets/DisFl-QA/spm_disfluent.model')\n",
    "sp_ori = spm.SentencePieceProcessor(model_file='./Datasets/DisFl-QA/spm_original.model')\n",
    "sp_all = spm.SentencePieceProcessor(model_file='./Datasets/DisFl-QA/spm.model')\n",
    "enc = sp_all.Encode('how long did julia butterfly hill live near a nuclear-missile installation?')\n",
    "sp_all.Decode(enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebdec86",
   "metadata": {},
   "source": [
    "## Set model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3286879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Hyperparameters ---\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "torch.set_num_threads(1)\n",
    "torch.manual_seed(seed=0)\n",
    "\n",
    "MODEL_NAME = 'LSTM_BI_ED_FINETUNE'\n",
    "\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8330e7",
   "metadata": {},
   "source": [
    "## Dataset preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d89ca56",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DisflQA(file_name='Datasets/Disfl-QA/train.json', max_len=100, return_len=False)\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=8, num_workers=2, shuffle=True)\n",
    "\n",
    "val_dataset = DisflQA(file_name='Datasets/Disfl-QA/dev.json', max_len=100, return_len=False)\n",
    "val_loader = data.DataLoader(val_dataset, batch_size=8, num_workers=2)\n",
    "\n",
    "src_vocab_emb = WordEmbedding(len(train_dataset.src_vocab), 256, 0.2)\n",
    "tgt_vocab_emb = WordEmbedding(len(train_dataset.tgt_vocab), 256, 0.2)\n",
    "\n",
    "# if an attribute error occurs, run the import cell again and continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38c0b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab_emb.dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a014da",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_vocab_emb.dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55135ff4",
   "metadata": {},
   "source": [
    "## Model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217dfae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM_ED(src_vocab_emb, tgt_vocab_emb, emb_dim=256, hid_dim=256, n_layers=4, dropout=0.1).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b026f21",
   "metadata": {},
   "source": [
    "## optimizers, loss function and normalizer for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e23e7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossLoss(nn.Module):\n",
    "    def __init__(self, ignore_index=-1):\n",
    "        super().__init__()\n",
    "        self.CrossLoss = nn.CrossEntropyLoss(ignore_index=ignore_index)\n",
    "\n",
    "    def forward(self, output, target):\n",
    "        output = torch.log(output)  \n",
    "        output = output.reshape(-1, output.shape[-1])  \n",
    "        target = target.reshape(-1).long() \n",
    "        return self.CrossLoss(output, target)\n",
    "\n",
    "class CrossLost(nn.Module):\n",
    "    def __init__(self, ignore_index=-1):\n",
    "        super().__init__()\n",
    "        self.CrossLoss = CrossLoss(ignore_index=ignore_index)\n",
    "\n",
    "    def forward(self, output, target):\n",
    "        output = output[:,:-1,:]\n",
    "        target = target[:,1:] \n",
    "        return self.CrossLoss(output, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84a1b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3)\n",
    "criterion = CrossLost(ignore_index=3)\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "scheduler = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0399b8",
   "metadata": {},
   "source": [
    "## Initial state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32d2fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = -1\n",
    "best_loss = 1e9\n",
    "history = {\n",
    "    'train_loss': [], \n",
    "    'val_loss': []\n",
    "}\n",
    "\n",
    "print('Total Parameters: {}'.format(sum(p.numel() for p in model.parameters())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99653ece",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de1d91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(tolerance=3, min_delta=2)\n",
    "\n",
    "value = os.path.exists('Model/{}.pt'.format(MODEL_NAME))\n",
    "if value:\n",
    "    os.remove('Model/{}.pt'.format(MODEL_NAME))\n",
    "    \n",
    "for i in range(start_epoch+1,EPOCHS):\n",
    "    print('Epoch {}:'.format(i))\n",
    "    train_loss = train(train_loader, model, optimizer, criterion, scheduler, device='cuda', scaler=scaler, kw_src=['input','output'])\n",
    "    val_loss = test(val_loader, model, criterion, device='cuda', return_results=False, kw_src=['input','output'])\n",
    "\n",
    "    # Log of loss values\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    \n",
    "    # early stopping\n",
    "    early_stopping(train_loss, val_loss)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"We are at epoch:\", i)\n",
    "        break\n",
    "\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        save('Model/{}.pt'.format(MODEL_NAME), model, optimizer, epoch=i, stats={'val_loss': best_loss, 'history': history})\n",
    "save('Model/{}_epoch_{}.pt'.format(MODEL_NAME,i), model, optimizer, epoch=i, stats={'val_loss': best_loss, 'history': history})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74442d98",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e7db5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "value = os.path.exists('Model/{}.pt'.format(MODEL_NAME))\n",
    "if value:\n",
    "    pass\n",
    "else:\n",
    "    print(\"Model not available in directory\")\n",
    "\n",
    "start_epoch, stats = load('Model/{}_epoch_19.pt'.format(MODEL_NAME), model, optimizer)\n",
    "best_loss = stats['val_loss']\n",
    "history = stats['history']\n",
    "\n",
    "# updating the graph\n",
    "plt.ylabel('Loss Value')\n",
    "plt.xlabel('Number of Epoch') \n",
    "plt.plot(np.arange(len(history['train_loss'])), history['train_loss'], linestyle='--', color='g', label='Train Loss')\n",
    "plt.plot(np.arange(len(history['val_loss'])), history['val_loss'], linestyle='--', color='r', label='Validation Loss')\n",
    "plt.legend() \n",
    "plt.savefig('Results/Loss_{}.png'.format(MODEL_NAME))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3a306f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bleu(nn.Module):\n",
    "    def __init__(self, ignore_index=-1):\n",
    "        super().__init__()\n",
    "        self.bleu = 'a'\n",
    "        \n",
    "    def forward(self, output, target):\n",
    "        bleu_1 = corpus_bleu(target, output, weights=(1.0,0,0,0))\n",
    "        bleu_2 = corpus_bleu(target, output, weights=(0.5,0.5,0,0))\n",
    "        bleu_3 = corpus_bleu(target, output, weights=(0.3,0.3,0.3,0))\n",
    "        bleu_4 = corpus_bleu(target, output, weights=(0.25,0.25,0.25,0.25))\n",
    "        return bleu_1, bleu_2, bleu_3, bleu_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3defa611",
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu = Bleu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74c7e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_bleu = []\n",
    "target_bleu = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f2b699",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = DisflQA(file_name='Datasets/Disfl-QA/test.json', max_len=100, return_len=False, infer=True)\n",
    "test_loader = data.DataLoader(test_dataset, batch_size=128, num_workers=2)\n",
    "\n",
    "_, outputs, targets = test(test_loader,model,device='cuda',return_results=True)\n",
    "outputs = outputs.numpy()\n",
    "targets = targets.numpy()\n",
    "\n",
    "write_input = open('Output/{}_log_inputs.txt'.format(MODEL_NAME), 'w', encoding='utf-8')\n",
    "write_output = open('Output/{}_log_outputs.txt'.format(MODEL_NAME), 'w', encoding='utf-8')\n",
    "write_target = open('Output/{}_log_targets.txt'.format(MODEL_NAME), 'w', encoding='utf-8')\n",
    "\n",
    "for i in range(len(test_dataset)):\n",
    "    str_input = test_dataset.src_vocab.decode(test_dataset[i][0].tolist())\n",
    "    str_target = test_dataset.tgt_vocab.decode(test_dataset[i][1].tolist())\n",
    "\n",
    "    post_process_output = []\n",
    "    for j in range(len(outputs[i])):\n",
    "        post_process_output.append(outputs[i][j])\n",
    "        if outputs[i][j] == 2:\n",
    "            break\n",
    "    post_process_output = np.array(post_process_output)        \n",
    "    str_output = test_dataset.tgt_vocab.decode(post_process_output.tolist())\n",
    "\n",
    "    write_input.write(str_input + '\\n')\n",
    "    write_output.write(str_output + '\\n')\n",
    "    write_target.write(str_target + '\\n')\n",
    "    \n",
    "    output_bleu.append(str_output.split())\n",
    "    target_bleu.append(str_target.split())\n",
    "    \n",
    "bleu_1, bleu_2, bleu_3, bleu_4 = bleu(target_bleu, output_bleu)\n",
    "print('BLEU-1 Loss : ', bleu_1)\n",
    "print('BLEU-2 Loss : ', bleu_2)\n",
    "print('BLEU-3 Loss : ', bleu_3)\n",
    "print('BLEU-4 Loss : ', bleu_4)\n",
    "    \n",
    "\n",
    "write_input.close()\n",
    "write_output.close()\n",
    "write_target.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa6dc32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
